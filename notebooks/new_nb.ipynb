{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch import optim\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Unable to find 'C:\\Users\\ANSD\\OneDrive - Azubi Africa\\master\\DIT\\M2\\DL2\\corona_sent_anal_transformers\\notebooks\\./data/cleaned/nlp_clean.csv' at C:\\Users\\ANSD\\OneDrive - Azubi Africa\\master\\DIT\\M2\\DL2\\corona_sent_anal_transformers\\notebooks",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39;49m\u001b[39mcsv\u001b[39;49m\u001b[39m\"\u001b[39;49m, data_files \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m./data/cleaned/nlp_clean.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, sep \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m\"\u001b[39;49m, encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mISO-8859-1\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m checkpoint \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbert-base-cased\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(checkpoint)\n",
      "File \u001b[1;32mc:\\Users\\ANSD\\anaconda3\\lib\\site-packages\\datasets\\load.py:1773\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[0;32m   1768\u001b[0m verification_mode \u001b[39m=\u001b[39m VerificationMode(\n\u001b[0;32m   1769\u001b[0m     (verification_mode \u001b[39mor\u001b[39;00m VerificationMode\u001b[39m.\u001b[39mBASIC_CHECKS) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m save_infos \u001b[39melse\u001b[39;00m VerificationMode\u001b[39m.\u001b[39mALL_CHECKS\n\u001b[0;32m   1770\u001b[0m )\n\u001b[0;32m   1772\u001b[0m \u001b[39m# Create a dataset builder\u001b[39;00m\n\u001b[1;32m-> 1773\u001b[0m builder_instance \u001b[39m=\u001b[39m load_dataset_builder(\n\u001b[0;32m   1774\u001b[0m     path\u001b[39m=\u001b[39mpath,\n\u001b[0;32m   1775\u001b[0m     name\u001b[39m=\u001b[39mname,\n\u001b[0;32m   1776\u001b[0m     data_dir\u001b[39m=\u001b[39mdata_dir,\n\u001b[0;32m   1777\u001b[0m     data_files\u001b[39m=\u001b[39mdata_files,\n\u001b[0;32m   1778\u001b[0m     cache_dir\u001b[39m=\u001b[39mcache_dir,\n\u001b[0;32m   1779\u001b[0m     features\u001b[39m=\u001b[39mfeatures,\n\u001b[0;32m   1780\u001b[0m     download_config\u001b[39m=\u001b[39mdownload_config,\n\u001b[0;32m   1781\u001b[0m     download_mode\u001b[39m=\u001b[39mdownload_mode,\n\u001b[0;32m   1782\u001b[0m     revision\u001b[39m=\u001b[39mrevision,\n\u001b[0;32m   1783\u001b[0m     use_auth_token\u001b[39m=\u001b[39muse_auth_token,\n\u001b[0;32m   1784\u001b[0m     storage_options\u001b[39m=\u001b[39mstorage_options,\n\u001b[0;32m   1785\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig_kwargs,\n\u001b[0;32m   1786\u001b[0m )\n\u001b[0;32m   1788\u001b[0m \u001b[39m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m \u001b[39mif\u001b[39;00m streaming:\n",
      "File \u001b[1;32mc:\\Users\\ANSD\\anaconda3\\lib\\site-packages\\datasets\\load.py:1502\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[1;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, use_auth_token, storage_options, **config_kwargs)\u001b[0m\n\u001b[0;32m   1500\u001b[0m     download_config \u001b[39m=\u001b[39m download_config\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m download_config \u001b[39melse\u001b[39;00m DownloadConfig()\n\u001b[0;32m   1501\u001b[0m     download_config\u001b[39m.\u001b[39muse_auth_token \u001b[39m=\u001b[39m use_auth_token\n\u001b[1;32m-> 1502\u001b[0m dataset_module \u001b[39m=\u001b[39m dataset_module_factory(\n\u001b[0;32m   1503\u001b[0m     path,\n\u001b[0;32m   1504\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m   1505\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[0;32m   1506\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[0;32m   1507\u001b[0m     data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[0;32m   1508\u001b[0m     data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[0;32m   1509\u001b[0m )\n\u001b[0;32m   1511\u001b[0m \u001b[39m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[0;32m   1512\u001b[0m builder_cls \u001b[39m=\u001b[39m import_main_class(dataset_module\u001b[39m.\u001b[39mmodule_path)\n",
      "File \u001b[1;32mc:\\Users\\ANSD\\anaconda3\\lib\\site-packages\\datasets\\load.py:1137\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[1;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[0;32m   1114\u001b[0m \u001b[39m# We have several ways to get a dataset builder:\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m   1116\u001b[0m \u001b[39m# - if path is the name of a packaged dataset module\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \n\u001b[0;32m   1129\u001b[0m \u001b[39m# Try packaged\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m \u001b[39mif\u001b[39;00m path \u001b[39min\u001b[39;00m _PACKAGED_DATASETS_MODULES:\n\u001b[0;32m   1131\u001b[0m     \u001b[39mreturn\u001b[39;00m PackagedDatasetModuleFactory(\n\u001b[0;32m   1132\u001b[0m         path,\n\u001b[0;32m   1133\u001b[0m         data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[0;32m   1134\u001b[0m         data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[0;32m   1135\u001b[0m         download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[0;32m   1136\u001b[0m         download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m-> 1137\u001b[0m     )\u001b[39m.\u001b[39;49mget_module()\n\u001b[0;32m   1138\u001b[0m \u001b[39m# Try locally\u001b[39;00m\n\u001b[0;32m   1139\u001b[0m \u001b[39melif\u001b[39;00m path\u001b[39m.\u001b[39mendswith(filename):\n",
      "File \u001b[1;32mc:\\Users\\ANSD\\anaconda3\\lib\\site-packages\\datasets\\load.py:712\u001b[0m, in \u001b[0;36mPackagedDatasetModuleFactory.get_module\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    706\u001b[0m base_path \u001b[39m=\u001b[39m (\n\u001b[0;32m    707\u001b[0m     \u001b[39mstr\u001b[39m(Path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_dir)\u001b[39m.\u001b[39mexpanduser()\u001b[39m.\u001b[39mresolve()) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_dir \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mstr\u001b[39m(Path()\u001b[39m.\u001b[39mresolve())\n\u001b[0;32m    708\u001b[0m )\n\u001b[0;32m    709\u001b[0m patterns \u001b[39m=\u001b[39m (\n\u001b[0;32m    710\u001b[0m     sanitize_patterns(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_files) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_files \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m get_data_patterns_locally(base_path)\n\u001b[0;32m    711\u001b[0m )\n\u001b[1;32m--> 712\u001b[0m data_files \u001b[39m=\u001b[39m DataFilesDict\u001b[39m.\u001b[39;49mfrom_local_or_remote(\n\u001b[0;32m    713\u001b[0m     patterns,\n\u001b[0;32m    714\u001b[0m     use_auth_token\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49muse_auth_token,\n\u001b[0;32m    715\u001b[0m     base_path\u001b[39m=\u001b[39;49mbase_path,\n\u001b[0;32m    716\u001b[0m )\n\u001b[0;32m    717\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_files \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39min\u001b[39;00m _MODULE_SUPPORTS_METADATA \u001b[39mand\u001b[39;00m patterns \u001b[39m!=\u001b[39m DEFAULT_PATTERNS_ALL:\n\u001b[0;32m    718\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ANSD\\anaconda3\\lib\\site-packages\\datasets\\data_files.py:783\u001b[0m, in \u001b[0;36mDataFilesDict.from_local_or_remote\u001b[1;34m(cls, patterns, base_path, allowed_extensions, use_auth_token)\u001b[0m\n\u001b[0;32m    780\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m()\n\u001b[0;32m    781\u001b[0m \u001b[39mfor\u001b[39;00m key, patterns_for_key \u001b[39min\u001b[39;00m patterns\u001b[39m.\u001b[39mitems():\n\u001b[0;32m    782\u001b[0m     out[key] \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 783\u001b[0m         DataFilesList\u001b[39m.\u001b[39;49mfrom_local_or_remote(\n\u001b[0;32m    784\u001b[0m             patterns_for_key,\n\u001b[0;32m    785\u001b[0m             base_path\u001b[39m=\u001b[39;49mbase_path,\n\u001b[0;32m    786\u001b[0m             allowed_extensions\u001b[39m=\u001b[39;49mallowed_extensions,\n\u001b[0;32m    787\u001b[0m             use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[0;32m    788\u001b[0m         )\n\u001b[0;32m    789\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(patterns_for_key, DataFilesList)\n\u001b[0;32m    790\u001b[0m         \u001b[39melse\u001b[39;00m patterns_for_key\n\u001b[0;32m    791\u001b[0m     )\n\u001b[0;32m    792\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\ANSD\\anaconda3\\lib\\site-packages\\datasets\\data_files.py:751\u001b[0m, in \u001b[0;36mDataFilesList.from_local_or_remote\u001b[1;34m(cls, patterns, base_path, allowed_extensions, use_auth_token)\u001b[0m\n\u001b[0;32m    742\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    743\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_local_or_remote\u001b[39m(\n\u001b[0;32m    744\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    748\u001b[0m     use_auth_token: Optional[Union[\u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    749\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDataFilesList\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    750\u001b[0m     base_path \u001b[39m=\u001b[39m base_path \u001b[39mif\u001b[39;00m base_path \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mstr\u001b[39m(Path()\u001b[39m.\u001b[39mresolve())\n\u001b[1;32m--> 751\u001b[0m     data_files \u001b[39m=\u001b[39m resolve_patterns_locally_or_by_urls(base_path, patterns, allowed_extensions)\n\u001b[0;32m    752\u001b[0m     origin_metadata \u001b[39m=\u001b[39m _get_origin_metadata_locally_or_by_urls(data_files, use_auth_token\u001b[39m=\u001b[39muse_auth_token)\n\u001b[0;32m    753\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(data_files, origin_metadata)\n",
      "File \u001b[1;32mc:\\Users\\ANSD\\anaconda3\\lib\\site-packages\\datasets\\data_files.py:349\u001b[0m, in \u001b[0;36mresolve_patterns_locally_or_by_urls\u001b[1;34m(base_path, patterns, allowed_extensions)\u001b[0m\n\u001b[0;32m    347\u001b[0m         data_files\u001b[39m.\u001b[39mappend(Url(pattern))\n\u001b[0;32m    348\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 349\u001b[0m         \u001b[39mfor\u001b[39;00m path \u001b[39min\u001b[39;00m _resolve_single_pattern_locally(base_path, pattern, allowed_extensions):\n\u001b[0;32m    350\u001b[0m             data_files\u001b[39m.\u001b[39mappend(path)\n\u001b[0;32m    352\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m data_files:\n",
      "File \u001b[1;32mc:\\Users\\ANSD\\anaconda3\\lib\\site-packages\\datasets\\data_files.py:293\u001b[0m, in \u001b[0;36m_resolve_single_pattern_locally\u001b[1;34m(base_path, pattern, allowed_extensions)\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[39mif\u001b[39;00m allowed_extensions \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    292\u001b[0m         error_msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m with any supported extension \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(allowed_extensions)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 293\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(error_msg)\n\u001b[0;32m    294\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msorted\u001b[39m(out)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Unable to find 'C:\\Users\\ANSD\\OneDrive - Azubi Africa\\master\\DIT\\M2\\DL2\\corona_sent_anal_transformers\\notebooks\\./data/cleaned/nlp_clean.csv' at C:\\Users\\ANSD\\OneDrive - Azubi Africa\\master\\DIT\\M2\\DL2\\corona_sent_anal_transformers\\notebooks"
     ]
    }
   ],
   "source": [
    "data = load_dataset(\"csv\", data_files = \"./data/cleaned/nlp_clean.csv\", sep = \",\", encoding='ISO-8859-1')\n",
    "checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data\\cleaned\\nlp_clean.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
